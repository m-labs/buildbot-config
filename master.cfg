# -*- python -*- # ex: set syntax=python:

# This is a sample buildmaster config file. It must be installed as
# 'master.cfg' in your buildmaster's base directory.

# This is the dictionary that the buildmaster pays attention to. We also use
# a shorter alias to save typing.
c = BuildmasterConfig = {}

# Don't store secrets bare in the configuration file.
import json
secrets = json.load(open('secrets.json'))

####### BUILDSLAVES

# The 'slaves' list defines the set of recognized buildslaves. Each element is
# a BuildSlave object, specifying a unique slave name and password.  The same
# slave name and password must be configured on the slave.
from buildbot.buildslave import BuildSlave

def merge(dicta, dictb):
    result = dict(dicta)
    result.update(dictb)
    return result

lin_properties = { 'dirsep': '/',  'pathsep': ':', 'condabindir': 'bin' }
win_properties = { 'dirsep': '\\', 'pathsep': ';', 'condabindir': 'Scripts' }

# without max_builds=1, conda build --output breaks horribly.
c['slaves'] = [
    BuildSlave('debian-stretch-amd64-1', secrets['slave_password'],
               properties=lin_properties, max_builds=1),
    BuildSlave('debian-stretch-amd64-2', secrets['slave_password'],
               properties=lin_properties, max_builds=1),
    # BuildSlave('debian-stretch-amd64-3', secrets['slave_password'],
    #            properties=lin_properties),
    BuildSlave('windows-7-x64-1', secrets['slave_password'],
               properties=win_properties, max_builds=1),
    BuildSlave('windows-7-x32-1', secrets['slave_password'],
               properties=win_properties, max_builds=1),
    BuildSlave('ubuntu-trusty-amd64-1', secrets['slave_password'],
               properties=lin_properties, max_builds=1),
]

buildslaves = {
    # To provision a Linux buildslave:
    #  * buildslave create-slave [name] localhost [name] [password]
    #  * install conda in .../miniconda/
    #  * source .../miniconda/bin/activate root
    #  * conda install -y conda-build anaconda-client
    #  * mkdir -p .../miniconda/conda-bld/linux-64
    #  * conda-index .../miniconda/conda-bld/linux-64
    'debian-stretch-amd64':
        ['debian-stretch-amd64-1', 'debian-stretch-amd64-2'],
    'ubuntu-trusty-amd64': ['ubuntu-trusty-amd64-1'],
    # To provision a Windows buildslave:
    #  * http://trac.buildbot.net/wiki/RunningBuildbotOnWindows
    #  * Install miniconda into .../miniconda/
    #  * set PATH=.../miniconda/Scripts;%PATH%
    #  * conda install -y conda-build anaconda-client
    #  * mkdir .../miniconda/conda-bld/win-64
    #  * conda-index .../miniconda/conda-bld/win-64
    'windows-7-x64': ['windows-7-x64-1'],
    'windows-7-x32': ['windows-7-x32-1'],
}

# 'slavePortnum' defines the TCP port to listen on for connections from slaves.
# This must match the value configured into the buildslaves (with their
# --master option)
c['slavePortnum'] = 9989

####### BUILDERS

# The 'builders' list defines the Builders, which tell Buildbot how to perform a build:
# what steps, and which slaves can execute them.  Note that any particular build will
# only take place on one slave.

import re, random, pysftp
from twisted.internet.threads import deferToThread
from buildbot import locks
from buildbot.process.properties import WithProperties
from buildbot.process.factory import BuildFactory
from buildbot.process.buildstep import BuildStep
from buildbot.status.builder import SUCCESS, FAILURE, SKIPPED
from buildbot.status.github import GitHubStatus
from buildbot.steps.source.git import Git
from buildbot.steps.shell import Configure, SetPropertyFromCommand, ShellCommand
from buildbot.steps.master import MasterShellCommand
from buildbot.steps.transfer import DirectoryUpload, StringDownload
from buildbot.steps.trigger import Trigger
from buildbot.process.properties import renderer
from steps import LitTestCommand, CoverallsCommand, XilinxCommand
from steps import SleepStep, FlockStep, FunlockStep

conda_lock = locks.SlaveLock('conda', maxCount=1)

# Steps requiring low latency should grab the lock exclusively
low_latency_lock = locks.MasterLock('low_latency', maxCount=2)
default_locks = [low_latency_lock.access('counting')]

def nextSlave(builder, slave_builders):
    def busyRatio(slave_builder):
        all_builders = slave_builder.slave.slavebuilders.values()
        active_builders = [sb for sb in all_builders if sb.isBusy()]
        return len(active_builders)

    return min(slave_builders, key=busyRatio)

conda_env_name = 'buildbot-%(buildername)s-%(buildnumber)s'
def condaEnv(use_local=False, extra_vars={}):
    local_bin_path = '%(dirsep)s'.join([
        '%(builddir)s', '..', 'miniconda',
        'envs', conda_env_name, '%(condabindir)s'
    ])

    global_bin_path = '%(dirsep)s'.join([
        '%(builddir)s', '..', 'miniconda', '%(condabindir)s'
    ])

    path_entries = [global_bin_path, '${PATH}']
    if use_local:
        path_entries.insert(0, local_bin_path)
    path = WithProperties('%(pathsep)s'.join(path_entries))

    env = {
        'PATH': path,
        'BUILDNUMBER': WithProperties('%(buildnumber)s'),
        # otherwise, conda's stdout and tests' stderr output interleaves badly.
        'PYTHONUNBUFFERED': '1'
    }
    env.update(extra_vars)
    return env

def addUpdateSteps(factory, project):
    factory.addStep(
        Git(repourl           = 'https://github.com/m-labs/{}'.format(project),
            submodules        = True,
            mode              = 'incremental',
            progress          = True))

def addCondaBuildSteps(factory, project, package, is_xilinx=False, test=True):
    addUpdateSteps(factory, project)

    factory.addStep(
        ShellCommand(
            name              = 'conda_clean',
            command           = ['conda', 'clean', '--index-cache'],
            description       = 'cleaning',
            descriptionDone   = 'clean',
            descriptionSuffix = 'conda cache',
            haltOnFailure     = True,
            env               = condaEnv(),
            locks             = default_locks +
                                [conda_lock.access('exclusive')]))

    factory.addStep(
        ShellCommand(
            name              = 'conda_build_purge',
            command           = ['conda', 'build', 'purge-all'],
            description       = 'purging',
            descriptionDone   = 'purge',
            descriptionSuffix = 'build dir',
            haltOnFailure     = True,
            env               = condaEnv(),
            locks             = default_locks +
                                [conda_lock.access('exclusive')]))

    build_cmd = ['conda', 'build', '--python', '3.5',
                 WithProperties('%(dirsep)s'.join(['conda', package]))]
    if not test:
        build_cmd.append('--no-test')

    def extractOutputNames(rc, stdout, stderr):
        filename = stdout.strip().split('\n')[-1]
        name, version, build = filename. \
            split('/')[-1]. \
            replace('.tar.bz2', ''). \
            rsplit('-', 2)
        return {
            'output_filename': filename,
            'output_name': name,
            'output_version': version,
            'output_build': build,
        }

    factory.addStep(
        SetPropertyFromCommand(
            name              = 'conda_build_output',
            command           = build_cmd + ['--output'],
            extract_fn        = extractOutputNames,
            description       = 'querying',
            descriptionSuffix = 'output name',
            haltOnFailure     = True,
            env               = condaEnv(),
            locks             = default_locks +
                                [conda_lock.access('exclusive')]))

    build_cls = (XilinxCommand if is_xilinx else ShellCommand)
    factory.addStep(
        build_cls(
            name              = 'conda_build',
            command           = build_cmd,
            description       = ['building', WithProperties(package)],
            descriptionDone   = ['build', WithProperties(package)],
            haltOnFailure     = True,
            timeout           = 60*60*4,
            env               = condaEnv(),
            locks             = default_locks +
                                [conda_lock.access('exclusive')]))

def addCondaUploadSteps(factory, channels, force=False):
    factory.addStep(
        ShellCommand(
            name              = 'anaconda_upload',
            command           = ['anaconda', 'upload',
                                 '--user', 'm-labs', '--channel', channels,
                                 WithProperties('%(output_filename)s')] +
                                (['--force'] if force else []),
            description       = 'uploading',
            descriptionDone   = 'upload',
            descriptionSuffix = 'package',
            env               = condaEnv(),
            locks             = default_locks))

def addCondaSetupTestEnvironmentSteps(factory, packages=['python'],
                                      update_deps=False, use_local=True):
    factory.addStep(
        ShellCommand(
            name              = 'conda_create',
            command           = ['conda', 'create',
                                 '-n', WithProperties(conda_env_name)] +
                                 map(WithProperties, packages) +
                                 ([] if update_deps else ['--no-update-deps']) +
                                 (['--use-local'] if use_local else []),
            description       = 'creating',
            descriptionDone   = 'create',
            descriptionSuffix = 'test environment',
            haltOnFailure     = True,
            env               = condaEnv(),
            locks             = default_locks +
                                [conda_lock.access('exclusive')]))

def addCondaInstallSteps(factory, packages=[],
                         update_deps=False, use_local=True):
    factory.addStep(
        ShellCommand(
            name              = 'conda_install',
            command           = ['conda', 'install',
                                 '-n', WithProperties(conda_env_name)] +
                                 map(WithProperties, packages) +
                                 ([] if update_deps else ['--no-update-deps']) +
                                 (['--use-local'] if use_local else []),
            description       = ['installing'] + packages,
            descriptionDone   = ['install'] + packages,
            haltOnFailure     = True,
            env               = condaEnv(use_local=True),
            locks             = default_locks +
                                [conda_lock.access('exclusive')]))

def addCondaTeardownTestEnvironmentSteps(factory):
    factory.addStep(
        ShellCommand(
            name              = 'conda_remove',
            command           = ['conda', 'remove',
                                 '-n', WithProperties(conda_env_name),
                                 '--all'],
            description       = 'destroying',
            descriptionDone   = 'destroy',
            descriptionSuffix = 'test environment',
            alwaysRun         = True,
            env               = condaEnv(),
            locks             = default_locks +
                                [conda_lock.access('exclusive')]))

def addPythonUnittestSteps(factory, locks=default_locks,
                           extra_vars={}, test_path='.'):
    factory.addStep(
        ShellCommand(
            name              = 'python_unittest',
            command           = ['python', '-m', 'unittest', 'discover', '-v', test_path],
            description       = 'testing',
            descriptionDone   = 'test',
            descriptionSuffix = test_path if test_path != "." else "",
            haltOnFailure     = True,
            env               = condaEnv(use_local=True,
                                         extra_vars=extra_vars),
            locks             = locks))

def addPythonCoverageSteps(factory, source_path, locks=default_locks,
                           extra_vars={}, test_path='.', warn_only=False):
    factory.addStep(
        ShellCommand(
            name              = 'python_coverage',
            command           = ['coverage', 'run', '--parallel-mode',
                                 '--source', source_path,
                                 '-m', 'unittest', 'discover', '-v', test_path],
            description       = 'testing',
            descriptionDone   = 'test',
            descriptionSuffix = test_path if test_path != "." else "",
            haltOnFailure     = not warn_only,
            flunkOnFailure    = not warn_only,
            warnOnFailure     = warn_only,
            env               = condaEnv(use_local=True,
                                         extra_vars=extra_vars),
            locks             = locks))

def addLitSteps(factory, test_path, extra_vars={}):
    factory.addStep(
        LitTestCommand(
            name              = 'lit_test',
            command           = ['lit', '-v', test_path],
            description       = 'testing',
            descriptionDone   = 'test',
            descriptionSuffix = 'lit',
            haltOnFailure     = True,
            env               = condaEnv(use_local=True,
                                         extra_vars=extra_vars),
            locks             = default_locks))

def addSphinxDocumentSteps(factory, source_path, target_path):
    factory.addStep(
        ShellCommand(
            name              = 'make_doc',
            command           = ['make', '-C', source_path, 'html'],
            description       = 'documenting',
            descriptionDone   = 'document',
            env               = condaEnv(use_local=True),
            locks             = default_locks))

    factory.addStep(
        DirectoryUpload(
            name              = 'upload_doc',
            slavesrc          = WithProperties('%(dirsep)s'.
                                    join([source_path, '_build', 'html'])),
            masterdest        = target_path,
            locks             = default_locks))


class DeployDocStep(BuildStep):
    renderables = ['source_path', 'target_path', 'username', 'password']

    def __init__(self, source_path, target_host,
                 username, password, target_path,
                 *args, **kwargs):
        BuildStep.__init__(self, *args, **kwargs)
        self.source_path = source_path
        self.target_host = target_host
        self.username    = username
        self.password    = password
        self.target_path = target_path

    def describe(self, done=False):
        return ['deploy' if done else 'deploying', 'doc']

    def start(self):
        deferred = deferToThread(self._upload)
        deferred.addCallback(lambda val: self.finished(SUCCESS))
        return deferred

    def _upload(self):
        with pysftp.Connection(self.target_host,
                               username=self.username,
                               password=self.password) as sftp:
            oldfiles, olddirs = [], []
            sftp.makedirs(self.target_path)
            sftp.walktree(self.target_path,
                          fcallback=lambda f: oldfiles.append(f),
                          ucallback=lambda f: oldfiles.append(f),
                          dcallback=lambda d: olddirs.append(d))
            for f in reversed(sorted(oldfiles)): sftp.unlink(f)
            for d in reversed(sorted(olddirs)):  sftp.rmdir(d)
            sftp.put_r(self.source_path, self.target_path)

def addSFTPUploadSteps(factory, source_path, target_host,
                       username, password, target_path):
    factory.addStep(
        DeployDocStep(
            name              = 'deploy_doc',
            source_path       = source_path,
            target_host       = target_host,
            username          = username,
            password          = password,
            target_path       = target_path,
            locks             = default_locks))

def addPythonCoverageCombineSteps(factory):
    factory.addStep(
        ShellCommand(
            name              = 'coverage_combine',
            command           = 'coverage combine',
            description       = 'combining',
            descriptionDone   = 'combine',
            descriptionSuffix = 'coverage',
            env               = condaEnv(use_local=True),
            locks             = default_locks))

def addCoverallsUploadSteps(factory, repo_token):
    factory.addStep(
        StringDownload(
            name              = 'coveralls_configure',
            description       = 'configuring',
            descriptionDone   = 'configure',
            descriptionSuffix = 'coveralls',
            s                 = WithProperties('service_job_id: "%(got_revision)s"'),
            slavedest         = '.coveralls.yml',
            locks             = default_locks))

    factory.addStep(
        CoverallsCommand(
            name              = 'coveralls_upload',
            description       = 'uploading',
            descriptionDone   = 'upload',
            descriptionSuffix = 'coveralls',
            flunkOnFailure    = False,
            warnOnFailure     = True,
            env               = condaEnv(extra_vars={
                'COVERALLS_REPO_TOKEN': repo_token
            }),
            locks             = default_locks))

def addARTIQFlashSteps(factory, options, address):
    factory.addStep(
        ShellCommand(
            name              = 'artiq_flash',
            command           = ['artiq_flash'] + options,
            description       = 'flashing',
            descriptionDone   = 'flash',
            haltOnFailure     = True,
            env               = condaEnv(use_local=True),
            locks             = default_locks))

    factory.addStep(
        SleepStep(
            delay             = 10.0,
            locks             = default_locks))

    factory.addStep(
        MasterShellCommand(
            name              = 'ping',
            command           = ['ping', address, '-c10', '-w30'],
            description       = ['pinging', address],
            descriptionDone   = ['ping', address],
            haltOnFailure     = True,
            locks             = default_locks))

    factory.addStep(
        ShellCommand(
            name              = 'artiq_corelog',
            command           = ['artiq_corelog', 'set_level', 'INFO'],
            description       = ['setting', 'log level'],
            descriptionDone   = ['set', 'log level'],
            haltOnFailure     = True,
            doStepIf          = lambda step: step.getProperty("branch") != "release-2",
            env               = condaEnv(use_local=True),
            workdir           = 'build/artiq/examples/master',
            locks             = default_locks))

def addFlockAcquireSteps(factory, board):
    factory.addStep(
        FlockStep(
            name              = 'board_lock',
            filename          = '/run/boards/{}'.format(board),
            haltOnFailure     = True,
            locks             = default_locks))

def addFlockReleaseSteps(factory, board):
    factory.addStep(
        FunlockStep(
            name              = 'board_unlock',
            filename          = '/run/boards/{}'.format(board),
            hideStepIf        = lambda result, step: result == SKIPPED,
            locks             = default_locks))

def addTriggerSteps(factory, builder_names, alwaysUseLatest,
                    waitForFinish=False,
                    copy_properties=[], set_properties={}):
    factory.addStep(
        Trigger(
            schedulerNames    = map(lambda name: 'trigger-{}'.format(name),
                                    builder_names),
            alwaysUseLatest   = alwaysUseLatest,
            waitForFinish     = waitForFinish,
            haltOnFailure     = waitForFinish,
            copy_properties   = copy_properties,
            set_properties    = set_properties))

from buildbot.config import BuilderConfig

c['builders'] = []

c['mergeRequests'] = True

c['validation'] = {
    'branch' : re.compile(r'^[\w.+/~-]*$'),
    'revision' : re.compile(r'^[ \w\.\-\/]*$'),
    'property_name' : re.compile(r'^[\w\.\-\/\~:]*$'),
    'property_value' : re.compile(r'^[\w\.\-\/\~=+:]*$'),
}

####### PYQTGRAPH

pyqtgraphBuildFactory = BuildFactory()
addCondaBuildSteps(pyqtgraphBuildFactory,
    project='pyqtgraph', package='pyqtgraph')
addCondaUploadSteps(pyqtgraphBuildFactory,
    force=True, channels='dev')

c['builders'].append(
    BuilderConfig(
        name       = 'pyqtgraph',
        slavenames = buildslaves['debian-stretch-amd64'],
        nextSlave  = nextSlave,
        factory    = pyqtgraphBuildFactory))

####### MIGEN
# apt-get install verilator

migenBuildFactory = BuildFactory()
# Build the `migen` package
addCondaBuildSteps(migenBuildFactory,
    project='migen', package='migen')
# Test the `migen` package
addCondaSetupTestEnvironmentSteps(migenBuildFactory,
    packages=['%(output_name)s', 'numpydoc', 'sphinx', 'sphinx_rtd_theme'])
addPythonUnittestSteps(migenBuildFactory)
# Upload the `migen` package
addCondaUploadSteps(migenBuildFactory,
    force=True, channels='dev')
# Upload the Migen documentation
addSphinxDocumentSteps(migenBuildFactory,
    source_path='doc',
    target_path='migen/manual')
addSFTPUploadSteps(migenBuildFactory,
    source_path='migen/manual',
    target_host='m-labs.hk',
    username=secrets['sftp']['username'],
    password=secrets['sftp']['password'],
    target_path='migen/manual')
# Teardown
addCondaTeardownTestEnvironmentSteps(migenBuildFactory)

c['builders'].append(
    BuilderConfig(
        name       = 'migen',
        slavenames = buildslaves['debian-stretch-amd64'],
        nextSlave  = nextSlave,
        factory    = migenBuildFactory))

####### MISOC

misocBuildFactory = BuildFactory()
# Build the `misoc` package
addCondaBuildSteps(misocBuildFactory,
    project='misoc', package='misoc')
# Upload the `misoc` package
addCondaUploadSteps(misocBuildFactory,
    force=True, channels='dev')

c['builders'].append(
    BuilderConfig(
        name       = 'misoc',
        slavenames = buildslaves['debian-stretch-amd64'],
        nextSlave  = nextSlave,
        factory    = misocBuildFactory))

####### ARTIQ

test_board_package  = 'artiq-kc705-nist_clock'
test_board_hostname = 'kc705.lab.m-labs.hk'

artiqBuildFactory = BuildFactory()
# Build and upload the `artiq-dev` package
addCondaBuildSteps(artiqBuildFactory,
    project='artiq', package='artiq-dev')
addCondaUploadSteps(artiqBuildFactory,
    force=True, channels='dev')
# Build the `artiq` package
addCondaBuildSteps(artiqBuildFactory,
    project='artiq', package='artiq', test=False)
# Test the `artiq` package
addCondaSetupTestEnvironmentSteps(artiqBuildFactory,
    packages=['%(output_name)s', 'artiq-dev=%(output_version)s'])
addPythonUnittestSteps(artiqBuildFactory,
    test_path='artiq/gateware/test')
addPythonCoverageSteps(artiqBuildFactory,
    source_path='artiq', test_path='artiq/test')
addLitSteps(artiqBuildFactory,
    test_path='artiq/test/lit',
    extra_vars={ 'COVERAGE': '1', 'PYTHONPATH': '.' })
# Upload the `artiq` package
addCondaUploadSteps(artiqBuildFactory,
    force=True, channels='dev')
# Build and upload the `artiq-board-*` package
addTriggerSteps(artiqBuildFactory,
    builder_names=["artiq-board"],
    alwaysUseLatest=False,
    waitForFinish=True,
    set_properties={"package": test_board_package})
# Test ARTIQ with hardware in the loop
addCondaInstallSteps(artiqBuildFactory,
    packages=[test_board_package])
addFlockAcquireSteps(artiqBuildFactory,
    board='kc705_1')
addARTIQFlashSteps(artiqBuildFactory,
    options=[],
    address=test_board_hostname)
addPythonCoverageSteps(artiqBuildFactory,
    source_path='artiq', test_path='artiq/test/coredevice',
    locks=[low_latency_lock.access('exclusive')],
    extra_vars={ 'ARTIQ_LOW_LATENCY': '1', 'ARTIQ_ROOT': 'artiq/examples/master' })
addPythonCoverageCombineSteps(artiqBuildFactory)
addCoverallsUploadSteps(artiqBuildFactory,
    repo_token=secrets['coveralls']['artiq'])
# Test ARTIQ on Windows with hardware in the loop
addTriggerSteps(artiqBuildFactory,
    builder_names=['artiq-win64-test'],
    alwaysUseLatest=False,
    waitForFinish=True,
    set_properties={ 'package': WithProperties('%(output_name)s') })
addFlockReleaseSteps(artiqBuildFactory,
    board='kc705_1')
# Build and upload ARTIQ documentation
addSphinxDocumentSteps(artiqBuildFactory,
    source_path='doc/manual',
    target_path='artiq/manual')
addSFTPUploadSteps(artiqBuildFactory,
    source_path='artiq/manual',
    target_host='m-labs.hk',
    username=secrets['sftp']['username'],
    password=secrets['sftp']['password'],
    target_path=WithProperties('artiq/manual-%(branch:~master)s'))
# Teardown
addCondaTeardownTestEnvironmentSteps(artiqBuildFactory)

c['builders'].append(
    BuilderConfig(
        name       = 'artiq',
        # Note the *-1 suffix: we don't want to ever have more than one
        # concurrent ARTIQ build, as that can lead to deadlocks downstream.
        slavenames = ['debian-stretch-amd64-1'],
        nextSlave  = nextSlave,
        properties = {'github_repo_name': 'artiq'},
        factory    = artiqBuildFactory))

artiqBoardBuildFactory = BuildFactory()
addCondaBuildSteps(artiqBoardBuildFactory,
    project='artiq', package='%(package)s', is_xilinx=True)
addCondaUploadSteps(artiqBoardBuildFactory,
    force=True, channels='dev')

c['builders'].append(
    BuilderConfig(
        name       = 'artiq-board',
        slavenames = ['debian-stretch-amd64-2'],
        nextSlave  = nextSlave,
        factory    = artiqBoardBuildFactory))

artiqWin64TestBuildFactory = BuildFactory()
addUpdateSteps(artiqWin64TestBuildFactory,
    project='artiq')
addCondaSetupTestEnvironmentSteps(artiqWin64TestBuildFactory,
    packages=['%(package)s', 'coverage'])
addPythonCoverageSteps(artiqWin64TestBuildFactory,
    source_path='artiq', test_path='artiq/test',
    locks=[low_latency_lock.access('exclusive')],
    extra_vars={ 'ARTIQ_LOW_LATENCY': '1', 'ARTIQ_ROOT': 'artiq\\examples\\master' },
    warn_only=True)
addPythonCoverageCombineSteps(artiqWin64TestBuildFactory)
addCoverallsUploadSteps(artiqWin64TestBuildFactory,
    repo_token=secrets['coveralls']['artiq'])
addCondaTeardownTestEnvironmentSteps(artiqWin64TestBuildFactory)

c['builders'].append(
    BuilderConfig(
        name       = 'artiq-win64-test',
        slavenames = buildslaves['windows-7-x64'],
        nextSlave  = nextSlave,
        factory    = artiqWin64TestBuildFactory))

####### Our Conda recipes

condaBuildFactory = BuildFactory()
addCondaBuildSteps(condaBuildFactory,
    project='conda-recipes', package='%(package)s')
addCondaUploadSteps(condaBuildFactory,
    channels='main')

c['builders'].append(
    BuilderConfig(
        name       = 'conda-lin64',
        slavenames = buildslaves['ubuntu-trusty-amd64'],
        nextSlave  = nextSlave,
        factory    = condaBuildFactory))

c['builders'].append(
    BuilderConfig(
        name       = 'conda-win64',
        slavenames = buildslaves['windows-7-x64'],
        nextSlave  = nextSlave,
        factory    = condaBuildFactory))

condaAllBuildFactory = BuildFactory()
addTriggerSteps(condaAllBuildFactory,
    ['conda-lin64', 'conda-win64'],
    alwaysUseLatest=True,
    waitForFinish=True,
    copy_properties=['package'])

c['builders'].append(
    BuilderConfig(
        name       = 'conda-all',
        slavenames = buildslaves['debian-stretch-amd64'],
        nextSlave  = nextSlave,
        factory    = condaAllBuildFactory))

####### Use this for experimentation

# playgroundBuildFactory = BuildFactory()
# addFlockAcquireSteps(playgroundBuildFactory,
#     board='kc705')
# playgroundBuildFactory.addStep(SleepStep(delay=60))
# addFlockReleaseSteps(playgroundBuildFactory,
#     board='kc705')

# c['builders'].append(
#     BuilderConfig(
#         name       = 'testbed',
#         slavenames = buildslaves['debian-stretch-amd64'],
#         nextSlave  = nextSlave,
#         factory    = playgroundBuildFactory))

####### SCHEDULERS

from buildbot.schedulers.forcesched import ForceScheduler
from buildbot.schedulers.basic import AnyBranchScheduler
from buildbot.schedulers.triggerable import Triggerable
from buildbot.changes.filter import ChangeFilter

c['schedulers'] = []

c['schedulers'].append(
    ForceScheduler(
        name            = 'force',
        builderNames    = map(lambda builder: builder.name, c['builders'])))

for builder in c['builders']:
    c['schedulers'].append(
        Triggerable(
            name         = 'trigger-{}'.format(builder.name),
            builderNames = [builder.name]))

for project in ['pyqtgraph', 'misoc', 'migen', 'artiq']:
    c['schedulers'].append(
        AnyBranchScheduler(
            name            = project,
            change_filter   = ChangeFilter(project='m-labs/' + project,
                                           branch_re=r'^(master$|release-\d+$)'),
            treeStableTimer = 1,
            builderNames    = [project]))

####### STATUS TARGETS

# 'status' is a list of Status Targets. The results of each build will be
# pushed to these targets. buildbot/status/*.py has a variety to choose from,
# including web pages, email senders, and IRC bots.

c['status'] = []

from buildbot.status import html, mail, words
from buildbot.status.web.authz import Authz
from buildbot.status.web.auth import BasicAuth

authz = Authz(
    auth                   = BasicAuth([(str(secrets['web']['username']),
                                         str(secrets['web']['password']))]),
    forceBuild             = 'auth',
    forceAllBuilds         = 'auth',
    stopBuild              = 'auth',
    stopAllBuilds          = 'auth',
    cancelPendingBuild     = 'auth',
    stopChange             = 'auth')

c['status'].append(
    html.WebStatus(
        http_port            = 'unix:/tmp/buildbot.sock',
        change_hook_dialects = {
                'github': {
                        'secret': secrets['web']['github'],
                        'strict': True,
                }
        },
        authz                = authz))

#c['status'].append(
#    mail.MailNotifier(
#        fromaddr = 'buildbot@m-labs.hk',
#        mode     = 'change'))

c['status'].append(
    words.IRC(
        'irc.freenode.net', 'bb-m-labs',
        channels        = ['#m-labs'],
        notify_events   = {
            'success'            : True,
            'warnings'           : True,
            'exception'          : True,
            'failure'            : True,
            'failureToSuccess'   : True,
            'exceptionToSuccess' : True,
            'warningsToSuccess'  : True,
        },
        noticeOnChannel = True,
        allowForce      = True))

c['status'].append(
    GitHubStatus(
        token=secrets['github']['status_api_token'],
        repoOwner='m-labs',
        repoName=WithProperties('%(github_repo_name:~)s')))

####### PROJECT IDENTITY

# the 'title' string will appear at the top of this buildbot
# installation's html.WebStatus home page (linked to the
# 'titleURL') and is embedded in the title of the waterfall HTML page.

c['title'] = 'ARTIQ'
c['titleURL'] = 'http://m-labs.hk/artiq'

# the 'buildbotURL' string should point to the location where the buildbot's
# internal web server (usually the html.WebStatus page) is visible. This
# typically uses the port number set in the Waterfall 'status' entry, but
# with an externally-visible host name which the buildbot cannot figure out
# without some help.

c['buildbotURL'] = 'http://buildbot.m-labs.hk/'

####### DB URL

c['db'] = {
    # This specifies what database buildbot uses to store its state.  You can leave
    # this at its default for all but the largest installations.
    'db_url' : 'sqlite:///state.sqlite3',
}
